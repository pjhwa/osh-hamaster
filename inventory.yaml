---
all:
  vars:
    ansible_port: 22
    ansible_user: citec
    ansible_ssh_private_key_file: /home/citec/.ssh/id_rsa
    ansible_ssh_extra_args: -o StrictHostKeyChecking=no -o ConnectTimeout=30 -o ServerAliveInterval=60 -o ServerAliveCountMax=5
    ansible_ssh_public_key_file: /home/citec/.ssh/id_rsa.pub
    ssh_public_key: "{{ lookup('file', '/home/citec/.ssh/id_rsa.pub') }}"
    kubectl:
      user: citec
      group: citec
    docker_users:
      - citec
    client_ssh_user: citec
    cluster_ssh_user: citec
    metallb_setup: true
    loopback_setup: true
    loopback_device: /dev/loop100
    loopback_image: /var/lib/openstack-helm/ceph-loop.img
    loopback_image_size: 12G
    vip: "172.16.2.148"
    control_plane_endpoint: "{{ vip }}:16443"
    kubeadm:
      service_cidr: "10.96.0.0/16"
      pod_network_cidr: "10.244.0.0/16"
    kube_version: "1.33.0"
    kube_version_repo: "v1.33"
    kube_package_version: "1.33.0-1.1"
    ingress_setup: true
  children:
    primary:
      hosts:
        k1:
          ansible_host: 172.16.2.149
          node_role: master
    k8s_cluster:
      hosts:
        k1:
          ansible_host: 172.16.2.149
          node_role: master
        k2:
          ansible_host: 172.16.2.52
          node_role: master_worker
        k3:
          ansible_host: 172.16.2.223
          node_role: master_worker
        k4:
          ansible_host: 172.16.2.161
          node_role: worker
    k8s_control_plane:
      hosts:
        k1:
          ansible_host: 172.16.2.149
          node_role: master
        k2:
          ansible_host: 172.16.2.52
          node_role: master_worker
        k3:
          ansible_host: 172.16.2.223
          node_role: master_worker
    k8s_nodes:
      hosts:
        k4:
          ansible_host: 172.16.2.161
          node_role: worker
